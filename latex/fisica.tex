\documentclass[../main.tex]{subfiles}

\begin{document}
Nonostante il traffico possa apparire un'argomento nettamente distaccato dalla fisica, vi \`e un forte legame nascosto.
\`E possibile, infatti, considerare ogni veicolo come una \emph{particella elementare} vincolata a muoversi su una traiettoria unidimensionale.
Questa particella deve ovviamente obbedire ad alcune regole: deve, ad esempio, spostarsi tra due punti $A$ e $B$ senza collidere con altre particelle.\\
Un modello di sistema complesso cos\`i definito \`e in grado di spiegare fisicamente fenomeni come le congestioni?

Negli ultimi 70 anni, diversi scienziati hanno sviluppato modelli e teorie sui flussi di traffico per comprenderne i fenomeni non lineari \cite{bs2004physics}.
I primi modelli sono stati sviluppati da Reushel (1950) e Pipes (1953), entrambi microscopici e rappresentanti il movimento di macchine in moto le une vicine alle altre su una strada a singola corsia.
Caratteristica in comune \`e l'assunzione che la velocit\`a di un veicolo dipenda linearmente sia dalla distanza dal veicolo precedente che dalla distanza dal successivo.
Nonostante l'ipotesi sembrasse ragionevole, la mancanza di conferme sperimentali sanc\`i il fallimento del modello.
Pochi anni dopo, nel 1955, Lighthill, un famoso teorico della meccanica dei fluidi, e Whitham proposero un modello macroscopico per i flussi di traffico, in analogia con il comportamento dei fluidi.
Le ipotesi alla base di questo modello sono la conservazione del numero di veicoli totali, ben giustificata, e l'esistenza di un'equazione di stato in grado di descrivere una relazione tra flusso di traffico (veh/h) e densit\`a (veh/km).
La seconda ipotesi, pur apparentemente ingiustificata, trov\`o presto conferme sperimentali.
Inoltre, il modello riusc\`i a spiegare fenomeni come le \emph{shock waves}, generate dal cambiamento del sistema verso uno stato con differenti densit\`a e flusso.
Nel 1958 vennero pubblicati i risultati della prima applicazione di un modello di \emph{car-following}.
Tale modello (e le rifiniture successive) si basa unicamente su concetti fisici: ogni veicolo viene descritto da una particella in un moto unidimensionale che accelerando varia la propria velocit\`a in base alla velocit\`a della particella che la precede.
I risultati dello studio evidenziarono una forte correlazione tra l'accelerazione dei veicoli e la velocit\`a dei precedenti, permettendo inoltre di stimare il tempo di reazione medio a $1$ s (basandosi unicamente sulle accelerazioni).
\`E stato successivaente dimostrato che, in un modello di \emph{car-following}, assumendo che ogni veicolo tenda a minimizzare l'integrale del quadrato della deviazione dal suo percorso ideale \`e possibile ottenere una formulazione lagrangiana del modello.
Nel 1967, Reuben Smeed fece osservare che in determinate circostanze, un veicolo potesse giungere ad una determinata destinazione in un tempo inferiore partendo pi\`u tardi: questo fenomeno \`e noto come paradosso di Smeed.
Un veicolo che si immette in una strada, infatti, ne aumenta la densit\`a riducendone di conseguenza il flusso e la velocit\`a media.
Smeed fece notare come, immettendosi in una determinata strada in un istante di tempo successivo, la densit\`a potesse essere diminuita nel frattempo: il veicolo potrebbe co\`i mantenere una velocit\`a superiore e percorrere il tratto in un tempo ridotto, compensando il ritardo in entrata.
La risoluzione sta nel fatto che l'immissione di un veicolo sulla strada non causa \emph{istantaneamente} una variazione di densit\`a, ma questo si cap\`i ad anni di distanza.
Un'ulteriore approccio venne introdotto nel 1971 con la creazione di un modello di traffico stile Boltzmann, basato su propriet\`a statisticamente distribuite nel sistema.\\
Altro problema inerente al traffico riguarda l'assegnazione del percorso ad ogni veicolo presente sulla rete.
Idealmente, ogni veicolo dovrebbe minimizzare il tempo di percorrenza calcolato dalla sorgente alla destinazione.
I primi contributi in questo ambito furono ad opera di Wardrop che nel 1952 propose due differenti principi su cui basare l'assegnazione del percorso.
Il primo principio prevedeva il medesimo tempo di percorrenza su ogni strada connettente sorgente e destinazione fissate e un tempo maggiore sulle strade inutilizzate.
Il secondo principio prevdeva, invece di minimizzare il tempo medio di percorrenza considerando tutto il network.
successivamente furono poi effettuati studi includendo ulteriori accortezze come effetti non lineari, perturbazioni e instabilit\`a, fino ad arrivare ad una teoria sull'assegnazione dinamica del traffico, in cui la generazione del traffico \`e una vera e propria funzione del tempo.
Gli algoritmi legati a questa teoria possono, tuttavia, condurre a paradossi come quello di Smeed e sono tuttora oggetto di studi.
% Fai qualche esempio dai, so che vuoi leggerti 200 paper diversi che parlano di traffico
Cos\`i come difetti e impurit\`a sono importanti per le transizioni di fase nei sistemi fisici, i \emph{bottleneck} (ingorghi) lo sono per i sistemi di traffico.
Le congestioni si verificano, infatti, prevalentemente laddove vi sono ingorghi.
Le cause di questi ultimi sono molteplici e spesso legate alla struttura stessa della strada: alcuni esempi possono essere una improvvisa riduzione delle corsie, cantieri stradali, curve, ecc.
Si \`e osservato che la capacit\`a di un sistema congestionato, ossia di un sistema nell'istante dopo un ingorgo, \`e inferiore alla capacit\`a del sistema stesso in condizioni di traffico libero: \`e il fenomeno chiamato \emph{capacity drop}.
Durante una congestione, si viene a creare il fenomeno di \emph{stop-and-go}, una sequenza di ingorghi differenti in movimento, ciascuno limitato spazialmente dal precedente e dal successivo.
All'interno di ogni ingorgo la velocit\`a media tende ad essere molto bassa (spesso anche nulla, da qui il nome \emph{stop-and-go}) e la densit\`a \`e molto alta.
Nelle congestioni sono stati osservati anche altri fenomeni, tra i quali rientrano anche cicli di isteresi.

I modelli di traffico trovarono presto diverse applicazioni nella realt\`a, non tutte con risultato positivo.
A New York fu limitato il traffico nel Lincoln Tunnel con un apposito computer, per evitare la creazione di congestioni al suoi interno.
Tuttavia, il progetto fall\`i in quanto causa delle congestioni era in realt\`a la struttura stessa del tunnel che, costringendo i veicoli a fermarsi e ripartire in alcuni punti, mise in evidenza un ciclo di isteresi dovuto alle differenti capacit\`a di accelerazione di veicoli pesanti e leggeri.
Anche Londra vennero utilizzati modelli di traffico per creare un piano di riurbanizzazione, poi abbandonato a causa dei costi elevati per la ricostruzione del sistema stradale.



\end{document}